/// # The matrix Dialect {#mat}
///
/// [TOC]
///
/// ## Dependencies
///
.import mem;
.import core;
.import math;
// needed to access cps2ds
.import direct;
.import affine;
///
/// ## Types
///
/// ### %matrix.Mat
///
/// a n-dimensional tensor with elements of type T
/// can be seen as generalization of Coq's vector type
///
/// matrix = Π [n: .Nat, S: «n; .Nat», T: *] -> *
/// matrix n S T = «Π_i=0^n S_i; T»
/// or 
/// matrix n S T = «S_0; «S_1; ... «S_{n-1}; T» ... »»
/// => a matrix is a dependend array
///
/// Alternative (current implementation):
/// matrix n S Ty = [i64, ..., i64, ptr(<T, Ty>)]
/// (currently with mem and as fat pointer without static size association:
///   [bit_field:i32, content:ptr(<T, Ty>), size_0:i64, size_1:i64])
/// * size: dependend vs i64 tuple
/// * shape: nested vs flat (n0*n1*...) elements
/// * mutability: mutable by nature vs mutable by its element type (liftet in thorin optimization / codegen)
///
/// advantage of opaque type for matrizes:
/// * prevent arbitrary read & insertions
/// 
/// depending on operations, one probably wants matrices to be a transparent definition instead of an opaque axiom
/// (currently: mat: [T: *] -> *)
.ax %matrix.Mat: Π [n: .Nat, S: «n; .Nat», T: *] -> *; 
///
/// ## Operations
///
/// ### %matrix.shape
/// 
/// gets the size along the i-th dimension
/// for a dependent matrix this is a simple projection
/// returns S(i)
///
/// normalization rules: 
/// * resolve shape calls at construction by replacing them with the size argument
.ax %matrix.shape:  Π [n: .Nat, S: «n; .Nat», T: *] -> [%matrix.Mat (n,S,T), i: .Idx n] -> .Nat, normalize_shape;
///
/// ### %matrix.prod
///
/// matrix product
/// takes a m*k matrix, a k*l matrix and returns the product, a m*l matrix
/// only defined on two-dimensional matrices
/// 
/// ### %matrix.map
///
/// unary elementwise operation
/// that lifts a function to the matrix level
/// f can not simply be T->P as thorin code is written in CPS
/// (currently (comment): Map: [dims: nat, in: *, out: *] -> [mat[] w] -> m64 w)
/// (currently: map: [mat_type: *, out_sigma: *, f_pi: *] -> [:mem, m: mat_type, f: f_ty] -> [:mem, out: out_sigma])
/// rewrite: 
/// - map on constant matrix
/// - parallel map without effect
/// - map combination
/// - map zipWith
/// 
/// ### %matrix.zip
///
/// binary elementwise operation
/// that lifts a binary function to the matrix level
/// same as map
/// rewrite: 
/// - zip on constant matrices
/// - parallel zip without effect
/// - zip combination
/// - zip with one side constant matrix
/// - meta_zip add zero m = m
/// (currently: hardcoded as matrix operations)
/// 
/// ### %matrix.fold
///
/// 
/// ### %matrix.const
///
/// a constant matrix
/// (currently: const i32 as bitfield)
.ax %matrix.constMat: Π [n: .Nat, S: «n; .Nat», T: *] -> [%mem.M,T] -> [%mem.M,%matrix.Mat (n,S,T)];
/// 
/// ### %matrix.transpose
///
/// transpose _ (m:@mat _ k*l T) : @mat _ l*k T
/// completely resolved during normalization and implicitely rewriting
/// (for instance: read(transpose m) (i,j) = read m (j,i))
///
/// transpose matrix
/// 
/// 
/// ### %matrix.id
///
/// id (k, m) : @mat _ (k,k) (Int m)
///
/// the idendity matrix
/// 
/// ### %matrix.read
///
/// read _ (mat, idx) : body_type
///
/// a access to an element of the matrix
/// (currently: arithmetic pointer access)
/// normalization:
/// * read(insert)
/// * read(const)
.ax %matrix.read: Π [n: .Nat, S: «n; .Nat», T: *] -> [%mem.M, %matrix.Mat (n,S,T), idx: «i: n; .Idx S#i»] -> [%mem.M,T], normalize_read;
/// 
/// ### %matrix.insert
///
/// insert (dims, sizes, type) (mat, idx, val) : mat
///
/// depending on matrix implementation needs mem monad
/// as it is implemented as write
/// for mutable body types, the monad should be liftet
/// implementation either as write or array insertion
/// normalization:
/// * with other inserts
/// * with initialization
.ax %matrix.insert: Π [n: .Nat, S: «n; .Nat», T: *] -> [%mem.M,%matrix.Mat (n,S,T), idx: «i: n; .Idx S#i», val: T] -> [%mem.M,%matrix.Mat (n,S,T)], normalize_insert;
///
/// ## Related operations
///
/// ### multiiter
///
/// iterated over n dimensions
/// takes:
/// * n: number of dimensions
/// * sizes: shape of the dimensions
/// * function: mem -> index -> mem
/// the function is taken in cps style
// .ax %matrix.multiiter: Π [n: .Nat, S: «n; .Nat»] -> 
//     .Cn[mem: %mem.M, body: .Cn[%mem.M, «i: n; .Idx (S#i)», .Cn[%mem.M]], .Cn[%mem.M]], normalize_multiiter;
///
/// ## Internal operations
/// 
/// ### %matrix.init
///
/// a fresh matrix 
.ax %matrix.init: Π [n: .Nat, S: «n; .Nat», T: *, %mem.M] -> [%mem.M,%matrix.Mat (n,S,T)];
///
/// ## Definitions and aliases
/// 
/// ### zero
// .lam .extern matrix_zero_int: Π [n: .Nat, S: «n; .Nat», m: .Nat] -> %matrix.Mat (n,S,(.Idx m)) = {
//     .tt,
//     %matrix.constMat (n,S,(.Idx m)) (0: (.Idx m))
// };
// .lam .extern matrix_zero: Π [n: .Nat, S: «n; .Nat», m: .Nat] -> %matrix.Mat (n,S,(%Real m)) = {
//     .tt,
//     %matrix.constMat (n,S,(%Real m)) (0: (%Real m))
// };
/// ### zip
///
/// zip A B = zipWith id A B
// .lam .extern zip: 
//     Π [n: .Nat, S: «n; .Nat», P: *, Q: *] -> 
//     [(%matrix.Mat(n,S,P)), (%matrix.Mat(n,S,Q))] -> 
//     %matrix.Mat(n,S,[P,Q]) = {
//     .tt,
//     .lam zipper: .Cn[mem: %mem.M, p: P, q: Q, ret: .Cn[%mem.M, [P,Q]]] = {
//         .tt,
//         ret (mem,(p,q))
//     };
//     .lam inner: 
//         Π [A: (%matrix.Mat(n,S,P)), B: (%matrix.Mat(n,S,Q))] -> 
//         %matrix.Mat(n,S,[P,Q]) = {
//         .tt,
//         %matrix.zipWith (n,S,P,Q,[P,Q]) (A,B,zipper)
//     };
//     inner
// };


/// ### fst, snd, split
// .lam .extern matrix_fst: 
//     Π [n: .Nat, S: «n; .Nat», P: *, Q: *] -> 
//     [M: (%matrix.Mat (n,S,[P,Q]))] -> 
//     %matrix.Mat (n,S,P) = {
//     .tt,
//     .lam fst : .Cn[mem: %mem.M, pq: [P,Q], ret: .Cn[%mem.M, P]] = {
//         .let (p,q) = pq;
//         ret (mem,p)
//     };
//     %matrix.map (n,S,[P,Q],P) (M,fst)
// };
// .lam .extern matrix_snd: 
//     Π [n: .Nat, S: «n; .Nat», P: *, Q: *] -> 
//     [M: (%matrix.Mat (n,S,[P,Q]))] -> 
//     %matrix.Mat (n,S,Q) = {
//     .tt,
//     .lam snd : .Cn[mem: %mem.M, pq: [P,Q], ret: .Cn[%mem.M, Q]] = {
//         .let (p,q) = pq;
//         ret (mem,q)
//     };
//     %matrix.map (n,S,[P,Q],Q) (M,snd)
// };
// .lam .extern matrix_split: 
//     Π [n: .Nat, S: «n; .Nat», P: *, Q: *] -> 
//     [M: (%matrix.Mat (n,S,[P,Q]))] -> 
//     [%matrix.Mat (n,S,P), %matrix.Mat (n,S,Q)] = {
//     .tt,
//     (
//         matrix_fst (n,S,[P,Q]) (M),
//         matrix_snd (n,S,[P,Q]) (M)
//     )
// };




// TODO:
// define alias:
// * fst, snd, split
// * zip = zipWith id
// .ax %matrix.id: Π [k: .Nat, m: .Nat] -> %matrix.Mat (2,(k,k),(.Idx m));
// .ax %matrix.transpose: Π [kl: «2: .Nat; .Nat», T: *] -> 
//     .let (k,l) = kl;
//     %matrix.Mat (2,(k,l),T) -> %matrix.Mat (2,(l,k),T), normalize_tranpose;
// .ax %matrix.fold:  Π [n: .Nat, S: «n; .Nat», T: *, P: *] -> [%matrix.Mat (n,S,T), accu: P, f: .Cn [%mem.M, P, T, .Cn [%mem.M, P] ] ] -> P, normalize_fold;
// .ax %matrix.zipWith:  Π [n: .Nat, S: «n; .Nat», P: *, Q: *, R: *] -> [%matrix.Mat(n,S,P), %matrix.Mat(n,S,Q), f: .Cn [%mem.M, P, Q, .Cn [%mem.M, R] ] ] -> %matrix.Mat(n,S,R), normalize_zip;
// .ax %matrix.parallel_zip:  Π [n: .Nat, S: «n; .Nat», P: *, Q: *, R: *] -> [%matrix.Mat n S P, %matrix.Mat n S Q, f: .Cn [P, Q, .Cn [R] ] ] -> %matrix.Mat n S R, normalize_parallel_zip;
// .ax %matrix.meta_zip:  Π [n: .Nat, S: «n; .Nat», P: *, Q: *, R: *] -> [%matrix.Mat n S P, %matrix.Mat n S Q, f: P -> Q -> R ] -> %matrix.Mat n S R, normalize_meta_zip;
// .ax %matrix.map:  Π [n: .Nat, S: «n; .Nat», T: *, P: *] -> [%matrix.Mat (n,S,T), f: .Cn [%mem.M, T, .Cn [%mem.M, P] ] ] -> %matrix.Mat (n,S,P), normalize_map;
// .ax %matrix.parallel_map:  Π [n: .Nat, S: «n; .Nat», T: *, P: *] -> [%matrix.Mat n S T, f: .Cn [T, .Cn [P] ] ] -> %matrix.Mat n S P, normalize_parallel_map;
// .ax %matrix.meta_map:  Π [n: .Nat, S: «n; .Nat», T: *, P: *] -> [%matrix.Mat n S T, f: T -> P ] -> %matrix.Mat n S P, normalize_meta_map;
.ax %matrix.prod:  Π [m: .Nat, k: .Nat, l: .Nat, [p: .Nat, e:.Nat]] -> 
    [%mem.M,%matrix.Mat (2,(m, k),%math.F (p,e)), %matrix.Mat (2,(k, l),%math.F (p,e))] -> [%mem.M,%matrix.Mat (2,(m, l),%math.F (p,e))], normalize_prod;
.ax %matrix.transpose: Π [[k:.Nat, l:.Nat], T: *] -> 
    [%mem.M,%matrix.Mat (2,(k,l),T)] -> [%mem.M,%matrix.Mat (2,(l,k),T)], normalize_transpose;

// .ax %matrix.sum: Π [n: .Nat, S: «n; .Nat», T: *] -> [%mem.M,%matrix.Mat (n,S,T)] -> [%mem.M,T];
.ax %matrix.sum: Π [n: .Nat, S: «n; .Nat», [p:.Nat,e:.Nat]] -> [%mem.M,%matrix.Mat (n,S,%math.F (p,e))] -> [%mem.M,%math.F (p,e)];


// TODO: handle reduction case
//  n=0, S=[] => not empty but scalar

// inspired by einsum
// reference:
// * Tensorflow / XLA: einsum
// * Pytorch: einsum
// * NumPy: einsum
// * Halide
// * Haskell: Tensor DSL
// * Ricci Calculus
// * Einstein Notation
// * Pytorch DSL
// https://optimized-einsum.readthedocs.io/en/stable/

// mapReduce application:
// * einsum(idx, MatrixIndices) = mapReduce(0,+,product,MatrixIndices)
// * map f M = mapReduce (0,+,f,[(idx,M)])  [TODO: get rid of reduce step if not needed with dummy values]
// * reduce acc f M = mapReduce (n=0) (acc,f,id,[(idx,M)])  [TODO: see index problem above]
// einsum application:
// * tranpose ij->ji  (einsum(,[(1,0),M]))
// * trace ii->
// * sum ij ->
// * col sum ij -> j 
// * mat vec prod ik,k->i
// * mat mat prod ik,kj -> ij
// * dot product i,i ->
// * dot matrix ij,ij ->
// * outer product i,j -> ij

// TODO: introduce dummies
// dummy = has correct type but can not produce code (should always be eliminated)
.ax %matrix.mapReduce: 
    // out shape depends on in shape but is complex
    Π [n: .Nat, S: «n; .Nat», T: *, // out shape
        m: .Nat, // number of inputs
        NI: «m; .Nat», // input dimensions
        TI: «m; *», // input types
        SI: «i:m; «NI#i; .Nat»» // input shapes
    ] -> 
    // main arguments
    [
        mem: %mem.M, // memory
        zero: T, // initial value
        // TODO: propagate change: no addition but instead take acc as argument (like mlir.linarith.generic)
        comb: .Cn[[%mem.M, T, «i: m; TI#i»],.Cn[%mem.M,T]], // inner combination
        // out_index not needed => always ij (0 ... n) for n dimensions
        input:
            «i:m; 
                [
                    «NI#i;.Nat»,
                    %matrix.Mat (NI#i,SI#i,TI#i)
                ]
            »
    ] ->
    [%mem.M, %matrix.Mat (n,S,T)],
    normalize_mapReduce;






// ///
// /// ## Unfolding functions
// /// 
// /// ### product
// /// 
// .lam .extern internal_mapRed_matrix_prod 
//     ![m: .Nat, k: .Nat, l: .Nat, w: .Nat] ->
//     (.Cn[
//         [%mem.M,%matrix.Mat (2,(m, k),%core.Real w), %matrix.Mat (2,(k, l),%core.Real w)],
//         .Cn[%mem.M,%matrix.Mat (2,(m, l),%core.Real w)]
//     ]) 
//     = {
//     .let R = %core.Real w;

//     .cn prod_comb [[mem:%mem.M, acc:R, [a:R, b:R]], ret:.Cn[%mem.M,R]] = {
//         .let v = %core.rop.mul (0, w) (a,b);

//         // reduce op = addition
//         .let new_acc = %core.rop.add (0, w) (acc,v);
//         ret (mem, new_acc)
//     };
//     .cn inner_matrix_prod 
//         ![
//             [
//                 mem:%mem.M,
//                 M:%matrix.Mat (2,(m, k),R), 
//                 N: %matrix.Mat (2,(k, l),R)
//             ],
//             ret: .Cn[%mem.M,%matrix.Mat (2,(m, l),R)]
//         ]
//     = {
//         .let zero_64 = 0.0:(%core.Real 64);
//         .let zero_real = %core.conv.r2r (w, 64) zero_64;
//         ret (
//             %matrix.mapReduce
//                 (2, (m, l), R, 
//                     2,
//                     (2, 2),
//                     (R,R),
//                     ((m,k),(k,l))
//                 )
//                 (
//                     mem,
//                     zero_real,
//                     prod_comb,
//                     (
//                         ((0,2), M),
//                         ((2,1), N)
//                     )
//                 )
//         )
//     };
//     inner_matrix_prod
// };
// /// 
// /// ### transpose
// /// 
// // TODO: check code for 1-matrix edge case
// // TODO: would this automatically be handled by read(transpose) ?
// .lam .extern internal_mapRed_matrix_transpose
//     ![[k: .Nat, l: .Nat], T:*] ->
//     (.Cn[
//         [%mem.M,%matrix.Mat (2,(k, l),T)],
//         .Cn[%mem.M,%matrix.Mat (2,(l, k),T)]
//     ]) 
//     = {
//     .con transpose_comb [[mem:%mem.M, acc:T, [a:T]], ret:.Cn[%mem.M,T]] = {
//         // TODO: or use generalized addition function
//         // ignore acc
//         .let new_acc = a;
//         ret (mem, new_acc)
//     };
//     .con inner_matrix_transpose
//         ![
//             [
//                 mem:%mem.M,
//                 M:%matrix.Mat (2,(k, l),T), 
//             ],
//             ret: .Cn[%mem.M,%matrix.Mat (2,(l, k),T)]
//         ]
//     = {
//         // TODO: use generalized zero
//         .let zero = (⊥:T);
//         ret (
//             %matrix.mapReduce
//                 (2, (l, k), T, 
//                     1,
//                     2,
//                     T,
//                     (k,l)
//                 )
//                 (
//                     mem,
//                     zero,
//                     transpose_comb,
//                     (
//                         ((1,0), M)
//                     )
//                 )
//         )
//     };
//     inner_matrix_transpose
// };
// /// 
// /// ### sum
// /// 
// // TODO: test 0d matrix (edge cases in code)
// .lam .extern internal_mapRed_matrix_sum
//     ![n: .Nat, S: «n; .Nat», w:.Nat] ->
//     (.Cn[
//         [%mem.M,%matrix.Mat (n,S,%core.Real w)],
//         .Cn[%mem.M,%core.Real w]
//     ]) 
//     = {
//     .let R = %core.Real w;
//     .cn sum_comb [[mem:%mem.M, acc:R, [a:R]], ret:.Cn[%mem.M,R]] = {
//         .let new_acc = %core.rop.add (0, w) (acc,a);
//         ret (mem, new_acc)
//     };
//     .cn inner_matrix_sum
//         ![
//             [
//                 mem:%mem.M,
//                 M:%matrix.Mat (n,S,R), 
//             ],
//             ret: .Cn[%mem.M,R]
//         ]
//     = {
//         // TODO: use generalized zero
//         .let zero_64 = 0.0:(%core.Real 64);
//         .let zero_real = %core.conv.r2r (w, 64) zero_64;
//         // should be normalized to lit tuple
//         // TODO: test normalization
//         .let idxs =
//             <i:n;
//             %core.nop.add (1,
//                 %core.bitcast (.Nat, .Idx n) i
//             )
//             >;
//         .let (mem2,res) = %matrix.mapReduce
//                 (1, (1), R, 
//                     1,
//                     n,
//                     R,
//                     S
//                 )
//                 (
//                     mem,
//                     zero_real,
//                     sum_comb,
//                     (
//                         (idxs, M)
//                     )
//                 );
//         ret (mem2,
//             %core.bitcast (
//                 R,
//                 %matrix.Mat (1,1,R)
//             ) res
//         )
//     };
//     inner_matrix_sum
// };



///
/// ## Compilation Passes and Phases
/// 
/// ### Passes
/// 
// .ax %matrix.lower_matrix_high_level_external: %compile.Pass;
.ax %matrix.lower_matrix_high_level_map_reduce: %compile.Pass;
.ax %matrix.lower_matrix_medium_level: %compile.Pass;
.ax %matrix.lower_matrix_low_level: %compile.Phase;
/// 
/// ### Phases
/// 
.let matrix_lower_phase = {
  %compile.phases_to_phase (⊤:.Nat)
    (
        (%compile.pass_phase (%compile.pass_list
            %matrix.lower_matrix_high_level_map_reduce
            %matrix.lower_matrix_medium_level
        )),
        %matrix.lower_matrix_low_level
        //   %compile.internal_cleanup_pass
    )
};
