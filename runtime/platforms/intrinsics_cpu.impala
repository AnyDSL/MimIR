extern "C" {
    fn expf(f32) -> f32;
    fn exp2f(f32) -> f32;
    fn logf(f32) -> f32;
    fn log2f(f32) -> f32;
    fn powf(f32, f32) -> f32;
    fn sqrtf(f32) -> f32;
    fn fabsf(f32) -> f32;
    fn tanf(f32) -> f32;
    fn atan2f(f32, f32) -> f32;
    fn sinf(f32) -> f32;
    fn cosf(f32) -> f32;
    fn asinf(f32) -> f32;
    fn acosf(f32) -> f32;
    fn erff(f32) -> f32;
    fn floorf(f32) -> f32;
    fn exp(f64) -> f64;
    fn pow(f64) -> f64;
    fn sqrt(f64) -> f64;
    fn fabs(f64) -> f64;
    fn tan(f64) -> f64;
    fn atan2(f64) -> f64;
    fn sin(f64) -> f64;
    fn cos(f64) -> f64;
    fn erf(f64) -> f64;
    fn floor(f64) -> f64;
}

// kind: Xchg Add Sub And Nand Or Xor Max Min
fn atomic_xchg(a: &i32, b: i32) -> i32 { atomic(0u, a, b) }
fn atomic_add(a: &i32, b: i32) -> i32 { atomic(1u, a, b) }
fn atomic_sub(a: &i32, b: i32) -> i32 { atomic(2u, a, b) }
fn atomic_min(a: &i32, b: i32) -> i32 { atomic(7u, a, b) }
fn atomic_max(a: &i32, b: i32) -> i32 { atomic(8u, a, b) }

extern "device" {
    fn "llvm.fma.f32" fmaf(f32, f32, f32) -> f32;
    fn "llvm.fmuladd.f32" madf(f32, f32, f32) -> f32;
    fn "llvm.fma.f64" fma(f64, f64, f64) -> f64;
    fn "llvm.fmuladd.f64" mad(f64, f64, f64) -> f64;
    fn "llvm.copysign.f32" copysignf(f32, f32) -> f32;
    fn "llvm.copysign.f64" copysign(f64, f64) -> f64;
}

fn rsqrtf(a: f32) -> f32 { 1.0f / sqrtf(a) }
fn rsqrt(a: f64) -> f64 { 1.0 / sqrt(a) }

fn fminf(a: f32, b: f32) -> f32 { if a < b { a } else { b } }
fn fmaxf(a: f32, b: f32) -> f32 { if a > b { a } else { b } }
fn fmin(a: f64, b: f64) -> f64 { if a < b { a } else { b } }
fn fmax(a: f64, b: f64) -> f64 { if a > b { a } else { b } }

extern "device" {
    fn "llvm.x86.sse.movmsk.ps" movmskps128(simd[f32 * 4]) -> i32;
    fn "llvm.x86.sse.cmp.ps" cmpps128(simd[f32 * 4], simd[f32 * 4], i8) -> simd[f32 * 4];
    fn "llvm.x86.sse.rcp.ps" rcpps128(simd[f32 * 4]) -> simd[f32 * 4];
    fn "llvm.x86.sse.rsqrt.ps" rsqrtps128(simd[f32 * 4]) -> simd[f32 * 4];

    fn "llvm.x86.avx.movmsk.ps.256" movmskps256(simd[f32 * 8]) -> i32;
    fn "llvm.x86.avx.cmp.ps.256" cmpps256(simd[f32 * 8], simd[f32 * 8], i8) -> simd[f32 * 8];
    fn "llvm.x86.avx.rcp.ps.256" rcpps256(simd[f32 * 8]) -> simd[f32 * 8];
    fn "llvm.x86.avx.rsqrt.ps.256" rsqrtps256(simd[f32 * 8]) -> simd[f32 * 8];
}

fn get_vector_length() -> int { 1 }
fn get_thread_number() -> int { 4 }
fn outer_loop(lower: int, upper: int, body: fn(int, fn())) -> () {
    for i in parallel(@get_thread_number(), lower, upper) {
        body(i);
    }
}
fn outer_loop_step(lower: int, upper: int, step: int, body: fn(int, fn())) -> () {
    for i in parallel(@get_thread_number(), 0, (upper-lower)/step) {
        body(i * step + lower);
    }
}
fn inner_loop(lower: int, upper: int, body: fn(int, fn())) -> () {
    if lower < upper {
        body(lower);
        inner_loop(lower+1, upper, body, return)
    }
}
fn inner_loop_step(lower: int, upper: int, step: int, body: fn(int, fn())) -> () {
    if lower < upper {
        body(lower);
        inner_loop_step(lower+step, upper, step, body, return)
    }
}
