/// # The tensor Plugin {#tensor}
///
/// @see mim::plug::tensor
///
/// [TOC]
///
/// ## Dependencies
///
plugin tuple;
plugin refly;
plugin vec;
///
/// A tensor plugin
///
/// ## Types
///
/// Represents an [algebraic Ring](https://en.wikipedia.org/wiki/Ring_(mathematics)).
///
let Ring = [
    T: *,
    _0: T,
    add: [T, T] → T,
    mul: [T, T] → T,
];
///
/// ## Operations
///
/// ### %%tensor.prod_2d
///
/// let nat_ring = (Nat, 0, 1, %core.nat.add, %core.nat.mul);
///
///
/// ### %%tensor.slice
///
axm %tensor.slice:  {T: *}
                  → {r: Nat, s: «r; Nat»}
                  → [input: «s;T», output_shape: «r; Nat», start_indices: «i :r; Idx (s#i)», steps: «i: r; Nat»]
                  → «output_shape; T»;
///
/// ### %%tensor.reduce
///
/// `ni` tensors each of shape `s` and type `Is#i` in arg is
/// * i: ni is a notation for i : (Idx ni)
///
axm %tensor.reduce: {r: Nat, s: «r; Nat», ni: Nat, Is: «ni; *»}
                  → [f: «2; «i: ni; Is#i» » → «i: ni; Is#i», init: «i: ni; Is#i»]
                  → [is: «i: ni; «s; Is#i» », dims: «r; Bool»]
                  → «i: ni; « <j: r; (s#j, 1)#(dims#j)>; Is#i» »;
/// ### %%tensor.map_reduce
///
/// * `nis`: number of inputs
/// * `T/R/S``is/o` : respectively the type/rank/shape of the inputs/output
/// * `f` : function to reduce over (takes an element of type `To` and one of each type in `Tis`, and returns a `To`)
/// * `init` : accumulator to start `f` with
/// * `subs` : for each input, for each dimension, an index to compute the output in Einstein notation
/// * `is` : the inputs
///
/// Returns a tensor obtained by folding `f` following the indexes in `subs`
///
axm %tensor.get: {T: *, r: Nat, s: «r; Nat»} → [arr: «s; T», index: «i: r; Idx (s#i)»] → T, normalize_get;

axm %tensor.set: {T: *, r: Nat, s: «r; Nat»} → [arr: «s; T», index: «i: r; Idx (s#i)», x: T] → «s; T», normalize_set;

axm %tensor.map_reduce: {nis: Nat}
                      → {To: *, Ro: Nat}
                      → [So: «Ro; Nat»]
                      → {Tis: «nis; *», Ris: «i: nis; Nat», Sis: «i:nis; «Ris#i; Nat»»}
                      → [f: Fn [To, «i: nis; Tis#i»] → [To], init: To]
                      → [subs: «i: nis; « Ris#i; Nat»»]
                      → [is: «i: nis; «Sis#i; Tis#i» »]
                      → «So; To», normalize_map_reduce;

fun dot_general_fun [R: Ring] [x: R#T, [y: R#T, z: R#T]]: R#T = return (R#add (x, (R#mul (y, z))));

lam dot_general_pick {n: Nat} {na nb nc: Nat} (a: «na; Idx n», b: «nb; Idx n», c: «nc; Idx n») (off_1 off_2: Nat) (i: Idx n): Nat =
  let (ab, ai) = %vec.first (%core.icmp.e @n) (a, i);
  let (bb, bi) = %vec.first (%core.icmp.e @n) (b, i);
  let (cb, ci) = %vec.first (%core.icmp.e @n) (c, i);
  let ai_nat = %core.bitcast Nat ai;
  let ai_out = %core.nat.add (off_1, ai_nat);
  let bi_nat = %core.bitcast Nat bi;
  let ci_nat = %core.bitcast Nat ci;
  let ci_out = %core.nat.add (off_2, ci_nat);
  ((ai_out, ci_out)#cb, bi_nat)#bb;

lam type {T: *} [x: T]: * = T; 

lam %tensor.dot_shape {r1 r2: Nat} {nc nb: Nat}
  [c1: «nc; Idx r1», c2: «nc; Idx r2», b1: «nb; Idx r1», b2: «nb; Idx r2»]
  [s1: «r1; Nat», s2: «r2; Nat»]: 
      let bs       = ‹i: nb; s1#(b1#i)›;
      let bc_1     = %tuple.cat_uniform (b1, c1);
      let s1_res   = %vec.diff (s1, bc_1);
      let n_s1_res = %vec.len s1_res;
      let bc_2     = %tuple.cat_uniform (b2, c2);
      let s2_res   = %vec.diff (s2, bc_2);
      let n_s2_res = %vec.len s2_res;
      let s12_res  = %tuple.cat_uniform (s1_res, s2_res);
      let s_out    = %tuple.cat_uniform (bs, s12_res);
      type s_out =
      let bs       = ‹i: nb; s1#(b1#i)›;
      let bc_1     = %tuple.cat_uniform (b1, c1);
      let s1_res   = %vec.diff (s1, bc_1);
      let n_s1_res = %vec.len s1_res;
      let bc_2     = %tuple.cat_uniform (b2, c2);
      let s2_res   = %vec.diff (s2, bc_2);
      let n_s2_res = %vec.len s2_res;
      let s12_res  = %tuple.cat_uniform (s1_res, s2_res);
      let s_out    = %tuple.cat_uniform (bs, s12_res);
      s_out;
  

lam %tensor.dot_general
  [R: Ring] {r1 r2: Nat} {nc nb: Nat}
  [c1: «nc; Idx r1», c2: «nc; Idx r2», b1: «nb; Idx r1», b2: «nb; Idx r2»]
  {s1: «r1; Nat», s2: «r2; Nat»} [a: «s1; R#T», b: «s2; R#T»]
    : let s_out = %tensor.dot_shape (c1, c2, b1, b2) (s1, s2);
      «s_out; R#T»
    = let s_out    = %tensor.dot_shape (c1, c2, b1, b2) (s1, s2);
      let bc_1     = %tuple.cat_uniform (b1, c1);
      let s1_res   = %vec.diff (s1, bc_1);
      let n_s1_res = %vec.len s1_res;
      let bc_2     = %tuple.cat_uniform (b2, c2);
      let f        = dot_general_fun R;
      let r_out    = %vec.len s_out;
      let a1       = %vec.diff (‹i: r1; i›, bc_1);
      let a2       = %vec.diff (‹i: r2; i›, bc_2);
      let ein_1    = ‹i: r1; dot_general_pick (a1, b1, c1) (nb, r_out) i›;
      let off_ein2 = %core.nat.add (nb, n_s1_res);
      let ein_2    = ‹i: r2; dot_general_pick (a2, b2, c2) (off_ein2, r_out) i›;
      %tensor.map_reduce @2 s_out (f, R#_0) (ein_1, ein_2) (a, b);

lam %tensor.prod_2d (R: Ring) {m k l: Nat} (t1: «m, k; R#T», t2: «k, l; R#T»): «m, l; R#T»
        = %tensor.dot_general R @(2, 2) (1_2, 0_2, (), ()) @((m, k), (k, l)) (t1, t2);
///
/// ### %%tensor.transpose
///
fun transpose_fun {T:*} [x: T, y: T]: T = return y;
///
lam %tensor.transpose {T: *, r: Nat, s: «r; Nat»}
                      [input: «s;T», permutation: «r; Idx r»]
                    :
                      let shape_permutation = ‹i: r; (%vec.first (%core.icmp.e @r) (permutation, i))#tt›;
                      let out_s = ‹i: r; s#(shape_permutation#i)›;
                      «out_s; T» =
                    let permutation_nat = <i: r; %core.bitcast Nat permutation#i>;
                    let shape_permutation = ‹i: r; (%vec.first (%core.icmp.e @r) (permutation, i))#tt›;
                    let out_s = ‹i: r; s#(shape_permutation#i)›;
                    %tensor.map_reduce @1 @(T, r) out_s @(T, r, s) (transpose_fun @T, ⊥: T) permutation_nat input;
///
/// ### %%tensor.broadcast
///
axm %tensor.broadcast:  {T: *, r: Nat}
                      → [s_in: «r; Nat», s_out: «r; Nat», «s_in; T»]
                      → «s_out; T», normalize_broadcast;
///
/// ### %%tensor.broadcast_in_dim
///
axm %tensor.broadcast_in_dim: {T: *, r_in r_out: Nat}
                            → [s_in: «r_in; Nat», s_out: «r_out; Nat», «s_in; T», «r_in; Idx r_out»]
                            → «s_out; T», normalize_broadcast_in_dim;
///
/// ### %%tensor.map
///
lam %tensor.map {T: *, ni: Nat, Is: «ni; *»}
                [app: «i: ni; Is#i» → T]
                {r: Nat, s: «r; Nat»}
                [is: «i: ni; «s; Is#i» »]
                : «s; T» =
  fun app_mr [x: T, y: «i: ni; Is#i»] = return (app y);
  %tensor.map_reduce @ni @(T, r) s @(Is, ‹ni; r›, ‹ni; s›) (app_mr, ⊥: T) ‹ni; ‹i:r; %core.bitcast Nat i›› is;
/// 
/// 
/// 
/// ### %%tensor.unary
/// 
lam %tensor.unary {Ti To : *} [app: Ti → To] {r: Nat, s: «r; Nat»} [i: «s; Ti»]: «s; To» =
  %tensor.map @(To, 1, Ti) app @(r, s) i;
/// 
/// ### %%tensor.binary
/// 
lam %tensor.binary {Ti1 Ti2 To: *} [app: [Ti1, Ti2] → To] {r: Nat, s: «r; Nat»} [is: [«s; Ti1», «s; Ti2»]]: «s; To» =
  %tensor.map @(To, 2, (Ti1, Ti2)) app @(r, s) is;
